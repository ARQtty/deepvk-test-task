{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime as dt\n",
    "from random import randint\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from hparams import Hparam\n",
    "from data.dataset import SpeechDataset\n",
    "from CPC.model import CPCModel\n",
    "# from CPC_classifiers.speaker_model import SpeakerClassificationCPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Hparam('./CPC/config.yaml')\n",
    "# config.train.device = 'cpu'\n",
    "gettime = lambda: str(dt.time(dt.now()))[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2703/2703 [00:00<00:00, 7480.06it/s]\n"
     ]
    }
   ],
   "source": [
    "ds = SpeechDataset(config.data.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26]) tensor([[-1.2491e-01, -1.0147e-01, -6.9641e-02,  ...,  7.3334e-02,\n",
      "          5.3802e-02,  3.0426e-02],\n",
      "        [-1.9836e-03,  1.8311e-04,  2.5330e-03,  ...,  7.8461e-02,\n",
      "          6.4392e-02,  4.5380e-02],\n",
      "        [-1.3733e-03, -1.8005e-03, -1.8616e-03,  ...,  3.8757e-03,\n",
      "          3.5095e-03,  2.5330e-03],\n",
      "        ...,\n",
      "        [ 7.7820e-03, -9.1553e-05, -6.6223e-03,  ..., -5.4779e-02,\n",
      "         -9.8572e-02, -1.3077e-01],\n",
      "        [-1.7276e-01, -9.8175e-02, -1.6388e-02,  ...,  6.1035e-03,\n",
      "         -9.4604e-03,  5.5542e-03],\n",
      "        [ 1.7242e-02, -1.6510e-02,  1.4587e-02,  ...,  2.7771e-03,\n",
      "          2.8381e-03,  2.3499e-03]])\n"
     ]
    }
   ],
   "source": [
    "train_dl = torch.utils.data.DataLoader(ds, batch_size=12)\n",
    "\n",
    "for b in train_dl:\n",
    "    sp, utt = b\n",
    "    print(sp, utt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cpc = CPCModel(config).to(config.train.device)\n",
    "# model_cpc.load_state_dict(torch.load('checkpoints/cpc_model_35_epoch.pt', map_location=config.train.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0482, -0.0498, -0.0497,  ..., -0.0154, -0.0147, -0.0119]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ds[27][1].unsqueeze(0).unsqueeze(0).to(config.train.device)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model_cpc.predict(sample)\n",
    "[t.size() for t in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "                                     Kernel Shape    Output Shape     Params  \\\n",
      "Layer                                                                          \n",
      "0_convolutions.Conv1d_0              [1, 512, 10]  [1, 512, 4095]     5.632k   \n",
      "1_convolutions.ReLU_1                           -  [1, 512, 4095]          -   \n",
      "2_convolutions.BatchNorm1d_2                [512]  [1, 512, 4095]     1.024k   \n",
      "3_convolutions.Conv1d_3             [512, 512, 8]  [1, 512, 1023]  2.097664M   \n",
      "4_convolutions.ReLU_4                           -  [1, 512, 1023]          -   \n",
      "5_convolutions.BatchNorm1d_5                [512]  [1, 512, 1023]     1.024k   \n",
      "6_convolutions.Conv1d_6             [512, 512, 4]   [1, 512, 512]  1.049088M   \n",
      "7_convolutions.ReLU_7                           -   [1, 512, 512]          -   \n",
      "8_convolutions.BatchNorm1d_8                [512]   [1, 512, 512]     1.024k   \n",
      "9_convolutions.Conv1d_9             [512, 512, 4]   [1, 512, 257]  1.049088M   \n",
      "10_convolutions.ReLU_10                         -   [1, 512, 257]          -   \n",
      "11_convolutions.BatchNorm1d_11              [512]   [1, 512, 257]     1.024k   \n",
      "12_convolutions.Conv1d_12           [512, 512, 4]   [1, 512, 128]  1.049088M   \n",
      "13_convolutions.ReLU_13                         -   [1, 512, 128]          -   \n",
      "14_convolutions.BatchNorm1d_14              [512]   [1, 512, 128]     1.024k   \n",
      "15_autoregressor                                -   [1, 128, 256]    591.36k   \n",
      "16_coupling_transforms.0.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "17_coupling_transforms.1.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "18_coupling_transforms.2.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "19_coupling_transforms.3.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "20_coupling_transforms.4.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "21_coupling_transforms.5.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "22_coupling_transforms.6.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "23_coupling_transforms.7.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "24_coupling_transforms.8.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "25_coupling_transforms.9.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "26_coupling_transforms.10.Conv1d_0  [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "27_coupling_transforms.11.Conv1d_0  [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "\n",
      "                                       Mult-Adds  \n",
      "Layer                                             \n",
      "0_convolutions.Conv1d_0                 20.9664M  \n",
      "1_convolutions.ReLU_1                          -  \n",
      "2_convolutions.BatchNorm1d_2               512.0  \n",
      "3_convolutions.Conv1d_3             2.145386496G  \n",
      "4_convolutions.ReLU_4                          -  \n",
      "5_convolutions.BatchNorm1d_5               512.0  \n",
      "6_convolutions.Conv1d_6              536.870912M  \n",
      "7_convolutions.ReLU_7                          -  \n",
      "8_convolutions.BatchNorm1d_8               512.0  \n",
      "9_convolutions.Conv1d_9              269.484032M  \n",
      "10_convolutions.ReLU_10                        -  \n",
      "11_convolutions.BatchNorm1d_11             512.0  \n",
      "12_convolutions.Conv1d_12            134.217728M  \n",
      "13_convolutions.ReLU_13                        -  \n",
      "14_convolutions.BatchNorm1d_14             512.0  \n",
      "15_autoregressor                        589.824k  \n",
      "16_coupling_transforms.0.Conv1d_0     33.554432M  \n",
      "17_coupling_transforms.1.Conv1d_0     33.554432M  \n",
      "18_coupling_transforms.2.Conv1d_0     33.554432M  \n",
      "19_coupling_transforms.3.Conv1d_0     33.554432M  \n",
      "20_coupling_transforms.4.Conv1d_0     33.554432M  \n",
      "21_coupling_transforms.5.Conv1d_0     33.554432M  \n",
      "22_coupling_transforms.6.Conv1d_0     33.554432M  \n",
      "23_coupling_transforms.7.Conv1d_0     33.554432M  \n",
      "24_coupling_transforms.8.Conv1d_0     33.554432M  \n",
      "25_coupling_transforms.9.Conv1d_0     33.554432M  \n",
      "26_coupling_transforms.10.Conv1d_0    33.554432M  \n",
      "27_coupling_transforms.11.Conv1d_0    33.554432M  \n",
      "------------------------------------------------------------------------------------------\n",
      "                            Totals\n",
      "Total params             8.998912M\n",
      "Trainable params         8.998912M\n",
      "Non-trainable params           0.0\n",
      "Mult-Adds             3.510171136G\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model_cpc.get_summary(sample.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## workbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = nn.Conv1d(5, 5, kernel_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor(1, 5, 166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c(t).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cpc.get_summary(ds[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model_cpc.predict(ds[1][1].unsqueeze(0).unsqueeze(0).cuda())\n",
    "[t.size() for t in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
