{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randint\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from hparams import Hparam\n",
    "from data.dataset import SpeechDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Hparam('./cpc_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPCModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CPCModel, self).__init__()\n",
    "        strides = [5, 4, 2, 2, 2]\n",
    "        kernels = [10,8, 4, 4, 4]\n",
    "        padding = [2, 2, 2, 2, 1]\n",
    "        self.predict_steps = config.model.predict_steps\n",
    "        channels = config.model.conv_channels\n",
    "        \n",
    "        \n",
    "        self.convolutions = []\n",
    "        for i in range(5):\n",
    "            dim = config.model.conv_channels\n",
    "            if i == 0:\n",
    "                dim = 1\n",
    "            self.convolutions.append(nn.Conv1d(dim, \n",
    "                                               channels, \n",
    "                                               kernels[i], \n",
    "                                               strides[i], \n",
    "                                               padding[i]))\n",
    "            self.convolutions.append(nn.ReLU())\n",
    "            self.convolutions.append(nn.BatchNorm1d(channels))\n",
    "        self.convolutions = nn.Sequential(*self.convolutions)    \n",
    "        \n",
    "        self.autoregressor = nn.GRU(channels, \n",
    "                                    config.model.context_size, \n",
    "                                    batch_first=True)\n",
    "        \n",
    "        self.coupling_transforms = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.Conv1d(\n",
    "                    channels, channels, kernel_size=1)\n",
    "            )\n",
    "            for steps in range(self.predict_steps)\n",
    "        ])\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size()[0]\n",
    "        for conv in self.convolutions:\n",
    "            x = conv(x)\n",
    "        \n",
    "        z = x.permute(0, 2, 1)\n",
    "        ctx, state = self.autoregressor(z)\n",
    "        z = z.permute(0, 2, 1)\n",
    "\n",
    "        \n",
    "        # https://github.com/ex4sperans/freesound-classification/blob/master/networks/cpc.py\n",
    "        logits = []\n",
    "        labels = []\n",
    "        for i in range(len(self.coupling_transforms)):\n",
    "            estimated = self.coupling_transforms[i](z)\n",
    "            #print('est shape', estimated.size())\n",
    "            \n",
    "            #print('before logit', 'z', z.size(), 'est', estimated.size())\n",
    "            logit = torch.bmm(z.permute(0, 2, 1), estimated) # b x f x f\n",
    "        \n",
    "            label = torch.eye(logit.size(2) - (i+1)).cuda()\n",
    "            label = F.pad(label, (0, i+1, i+1, 0))\n",
    "            label = label.unsqueeze(0).expand_as(logit)\n",
    "            \n",
    "            logits.append(logit)\n",
    "            labels.append(label)\n",
    "            \n",
    "        return logits, labels\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_accuracy(logits, labels):\n",
    "        with torch.no_grad():\n",
    "            logits[logits.ge(0.5)] = 1\n",
    "            logits[logits < 0.5] = 0\n",
    "            acc = (logits == labels).sum().float() / logits.numel()\n",
    "            return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28539/28539 [02:00<00:00, 237.25it/s]\n"
     ]
    }
   ],
   "source": [
    "ds = SpeechDataset(config.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CPCModel(config).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummaryX import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "                                     Kernel Shape    Output Shape     Params  \\\n",
      "Layer                                                                          \n",
      "0_convolutions.Conv1d_0              [1, 512, 10]  [1, 512, 4095]     5.632k   \n",
      "1_convolutions.ReLU_1                           -  [1, 512, 4095]          -   \n",
      "2_convolutions.BatchNorm1d_2                [512]  [1, 512, 4095]     1.024k   \n",
      "3_convolutions.Conv1d_3             [512, 512, 8]  [1, 512, 1023]  2.097664M   \n",
      "4_convolutions.ReLU_4                           -  [1, 512, 1023]          -   \n",
      "5_convolutions.BatchNorm1d_5                [512]  [1, 512, 1023]     1.024k   \n",
      "6_convolutions.Conv1d_6             [512, 512, 4]   [1, 512, 512]  1.049088M   \n",
      "7_convolutions.ReLU_7                           -   [1, 512, 512]          -   \n",
      "8_convolutions.BatchNorm1d_8                [512]   [1, 512, 512]     1.024k   \n",
      "9_convolutions.Conv1d_9             [512, 512, 4]   [1, 512, 257]  1.049088M   \n",
      "10_convolutions.ReLU_10                         -   [1, 512, 257]          -   \n",
      "11_convolutions.BatchNorm1d_11              [512]   [1, 512, 257]     1.024k   \n",
      "12_convolutions.Conv1d_12           [512, 512, 4]   [1, 512, 128]  1.049088M   \n",
      "13_convolutions.ReLU_13                         -   [1, 512, 128]          -   \n",
      "14_convolutions.BatchNorm1d_14              [512]   [1, 512, 128]     1.024k   \n",
      "15_autoregressor                                -   [1, 128, 256]    591.36k   \n",
      "16_coupling_transforms.0.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "17_coupling_transforms.1.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "18_coupling_transforms.2.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "19_coupling_transforms.3.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "20_coupling_transforms.4.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "21_coupling_transforms.5.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "22_coupling_transforms.6.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "23_coupling_transforms.7.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "24_coupling_transforms.8.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "25_coupling_transforms.9.Conv1d_0   [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "26_coupling_transforms.10.Conv1d_0  [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "27_coupling_transforms.11.Conv1d_0  [512, 512, 1]   [1, 512, 128]   262.656k   \n",
      "\n",
      "                                       Mult-Adds  \n",
      "Layer                                             \n",
      "0_convolutions.Conv1d_0                 20.9664M  \n",
      "1_convolutions.ReLU_1                          -  \n",
      "2_convolutions.BatchNorm1d_2               512.0  \n",
      "3_convolutions.Conv1d_3             2.145386496G  \n",
      "4_convolutions.ReLU_4                          -  \n",
      "5_convolutions.BatchNorm1d_5               512.0  \n",
      "6_convolutions.Conv1d_6              536.870912M  \n",
      "7_convolutions.ReLU_7                          -  \n",
      "8_convolutions.BatchNorm1d_8               512.0  \n",
      "9_convolutions.Conv1d_9              269.484032M  \n",
      "10_convolutions.ReLU_10                        -  \n",
      "11_convolutions.BatchNorm1d_11             512.0  \n",
      "12_convolutions.Conv1d_12            134.217728M  \n",
      "13_convolutions.ReLU_13                        -  \n",
      "14_convolutions.BatchNorm1d_14             512.0  \n",
      "15_autoregressor                        589.824k  \n",
      "16_coupling_transforms.0.Conv1d_0     33.554432M  \n",
      "17_coupling_transforms.1.Conv1d_0     33.554432M  \n",
      "18_coupling_transforms.2.Conv1d_0     33.554432M  \n",
      "19_coupling_transforms.3.Conv1d_0     33.554432M  \n",
      "20_coupling_transforms.4.Conv1d_0     33.554432M  \n",
      "21_coupling_transforms.5.Conv1d_0     33.554432M  \n",
      "22_coupling_transforms.6.Conv1d_0     33.554432M  \n",
      "23_coupling_transforms.7.Conv1d_0     33.554432M  \n",
      "24_coupling_transforms.8.Conv1d_0     33.554432M  \n",
      "25_coupling_transforms.9.Conv1d_0     33.554432M  \n",
      "26_coupling_transforms.10.Conv1d_0    33.554432M  \n",
      "27_coupling_transforms.11.Conv1d_0    33.554432M  \n",
      "------------------------------------------------------------------------------------------\n",
      "                            Totals\n",
      "Total params             8.998912M\n",
      "Trainable params         8.998912M\n",
      "Non-trainable params           0.0\n",
      "Mult-Adds             3.510171136G\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "t = ds[1][1].unsqueeze(0).unsqueeze(0)\n",
    "f = summary(model, t.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=config.train.lr)\n",
    "criterion = F.binary_cross_entropy_with_logits\n",
    "writer = SummaryWriter()\n",
    "dl = torch.utils.data.DataLoader(ds, config.train.batch_size, shuffle=True)\n",
    "abs_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 started\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-e424873e3de1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCPCModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss/loss_%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy/accuracy_%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-465417d9bdc2>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(logits, labels)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(1, config.train.epochs):\n",
    "    print('Epoch %2d started' % e)\n",
    "    \n",
    "    for i, batch in enumerate(dl):\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        speakers, utters = batch\n",
    "        logits, labels = model(utters.unsqueeze(1).cuda())\n",
    "        \n",
    "        for j in range(len(logits)):\n",
    "            loss = criterion(logits[j], labels[j])\n",
    "            loss.backward(retain_graph=True)\n",
    "            accuracy = CPCModel.get_accuracy(logits[j], labels[j])\n",
    "            writer.add_scalar('Loss/loss_%d' % j, loss.item(), abs_step)\n",
    "            writer.add_scalar('Accuracy/accuracy_%d' % j, accuracy.item(), abs_step)\n",
    "            \n",
    "        abs_step+=1\n",
    "        \n",
    "        opt.step()\n",
    "    \n",
    "    if e % config.train.save_every == 0:\n",
    "        torch.save(model.state_dict(), config.train.save_name + '_%d_epoch.pt' % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datetime.datetime'; 'datetime' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-6786ba31b93f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datetime.datetime'; 'datetime' is not a package"
     ]
    }
   ],
   "source": [
    "import datetime.datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07:46:10'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(t.datetime.time(t.datetime.now()))[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lds = torchaudio.datasets.LIBRISPEECH('/data/deepvk/librispeech/train-clean-100/', url='train-clean-100')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
